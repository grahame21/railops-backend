name: Update Train Data

on:
  schedule:
    # Every 5 minutes during peak hours (6am-10pm AEST)
    - cron: '*/5 20-13 * * *'
    # Every 15 minutes during off-peak (10pm-6am AEST)
    - cron: '*/15 14-19 * * *'
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          google-chrome-stable \
          xvfb \
          unzip \
          curl \
          jq
    
    - name: Check Chrome version
      run: |
        google-chrome --version
        which google-chrome
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install selenium requests webdriver-manager
    
    - name: Debug - List files
      run: |
        pwd
        ls -la
        echo "--- Python files ---"
        ls -la *.py || echo "No Python files found"
    
    - name: Debug - Check script syntax
      run: |
        python -m py_compile update_trains.py || echo "Syntax error in update_trains.py"
    
    - name: Run scraper with debug output
      env:
        TF_USERNAME: ${{ secrets.TF_USERNAME }}
        TF_PASSWORD: ${{ secrets.TF_PASSWORD }}
        DISPLAY: ":99"
        PYTHONUNBUFFERED: 1
      run: |
        # Start Xvfb
        Xvfb :99 -screen 0 1920x1080x24 &
        sleep 3
        
        # Run with full traceback
        python -u update_trains.py 2>&1 | tee scraper_output.log
        
        # Check exit code
        if [ ${PIPESTATUS[0]} -ne 0 ]; then
          echo "‚ùå Scraper failed with exit code ${PIPESTATUS[0]}"
          exit ${PIPESTATUS[0]}
        fi
    
    - name: Upload debug log on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-debug-log
        path: scraper_output.log
        retention-days: 7
    
    - name: Commit and push if changed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add trains.json
        if ! git diff --cached --quiet; then
          git commit -m "Update train data $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          git push
        else
          echo "No changes to commit"
        fi
