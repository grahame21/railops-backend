name: Update Train Data

on:
  schedule:
    # Peak hours (6am-10pm AEST) - every 5 minutes
    - cron: '*/5 20-13 * * *'
    # Off-peak (10pm-6am) - every 15 minutes
    - cron: '*/15 14-19 * * *'
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable xvfb
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install selenium requests
    
    - name: Add random delay (avoid detection)
      run: sleep $(( RANDOM % 120 ))
    
    - name: Run scraper
      env:
        TF_USERNAME: ${{ secrets.TF_USERNAME }}
        TF_PASSWORD: ${{ secrets.TF_PASSWORD }}
      run: xvfb-run -a python update_trains.py
    
    - name: Commit and push if changed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add trains.json
        if ! git diff --cached --quiet; then
          git commit -m "Update train data $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          git push
        fi
